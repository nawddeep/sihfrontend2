# AI-Powered Fraud Detection System - Implementation Guide

## üìã Overview

The AI-Powered Fraud Detection System is an advanced feature that enhances the SIH exam security platform with machine learning-based document authentication. It analyzes documents for fraud indicators using visual anomaly detection, biometric analysis, and institutional verification.

## üéØ Key Features

### 1. **Real-Time Document Scanning**
- Analyzes document structure and content
- Detects watermarks, signatures, and seals
- Checks for font consistency and formatting irregularities
- Simulates 1-2 second ML model latency

### 2. **Visual Anomaly Detection**
- Interactive heatmap overlay showing suspicious regions
- Color-coded severity levels (critical, high, medium, low)
- Pixel-level location mapping
- Adjustable intensity controls

### 3. **Explainable AI Results**
- Confidence scoring with model transparency
- Detailed breakdown of detected anomalies
- Biometric verification scores (face, fingerprint, liveness, anti-spoofing)
- Historical fraud comparison

### 4. **Risk Assessment**
- 4-tier risk level classification
- Automated recommendations (auto-verify, manual review, escalate, reject)
- Supporting evidence from multiple analysis dimensions

## üì¶ Component Structure

```
src/components/AIFraudDetection/
‚îú‚îÄ‚îÄ AIFraudDetector.jsx          # Main interface component
‚îú‚îÄ‚îÄ AnomalyVisualizer.jsx        # Heatmap visualization
‚îú‚îÄ‚îÄ ConfidenceScoreCard.jsx      # Explainable AI results
‚îú‚îÄ‚îÄ DetectionTimeline.jsx        # Process timeline
‚îî‚îÄ‚îÄ index.js                      # Barrel export
```

### Component Responsibilities

#### **AIFraudDetector.jsx** (Main Container)
- Orchestrates the entire detection workflow
- Manages state for detection results and progress
- Handles error states and recovery
- Displays overall risk assessment
- Provides re-run capability

**Props:**
```javascript
{
  documentId: string,              // Unique document identifier
  documentData: object,            // Document metadata (name, type, etc.)
  onDetectionComplete: function,   // Callback when analysis finishes
  onAnomalyClick: function        // Handler for anomaly selection
}
```

**Key Features:**
- Detection phase progression (idle ‚Üí scanning ‚Üí analyzing ‚Üí reporting ‚Üí complete)
- Animated confidence bars
- Biometric score display
- Recommendation display
- Export functionality placeholder

#### **AnomalyVisualizer.jsx** (Visual Analysis)
- Canvas-based heatmap rendering
- Severity-coded color overlays
- Interactive anomaly highlighting
- Intensity adjustment slider
- Responsive design

**Props:**
```javascript
{
  anomalies: Array,               // Array of detected anomalies
  selectedAnomaly: object,        // Currently selected anomaly
  documentImage: string          // URL to document image (optional)
}
```

#### **ConfidenceScoreCard.jsx** (Explainable AI)
- Tabbed interface (Overview, Analysis, History)
- Circular confidence gauge
- Biometric score display
- Anomaly breakdown
- Historical context

**Props:**
```javascript
{
  detection: object,              // Full detection result
  report: object                  // Explainable AI report
}
```

#### **DetectionTimeline.jsx** (Process Visualization)
- 4-step timeline visualization
- Real-time phase indication
- Animated progress indicators
- Status messages
- Accessible ARIA regions

**Props:**
```javascript
{
  phase: string                   // Current detection phase
}
```

## üîå Service Integration

### **aiDetectionService.js**

Provides mock ML model simulations with realistic behavior.

#### Core Functions

```javascript
/**
 * Main fraud detection function
 * @param documentId - Document identifier
 * @param documentMetadata - Optional metadata
 * @returns Promise with detection results
 */
detectFraud(documentId, documentMetadata)

/**
 * Generate explainable report
 * @param detectionResult - Result from detectFraud
 * @returns Promise with detailed report
 */
generateExplainableReport(detectionResult)

/**
 * Get detection history for document
 * @param documentId - Document identifier
 * @returns Promise with historical data
 */
getDetectionHistory(documentId)

/**
 * Compare with institutional template
 * @param documentId - Document identifier
 * @param institutionId - Institution identifier
 * @returns Promise with comparison results
 */
compareWithTemplate(documentId, institutionId)

/**
 * Batch process multiple documents
 * @param documentIds - Array of document IDs
 * @param onProgress - Progress callback
 * @returns Promise with batch results
 */
detectFraudBatch(documentIds, onProgress)
```

## üìä Data Structures

### Detection Result Object
```javascript
{
  documentId: string,
  fraudProbability: number (0-1),
  confidence: number (85-100),
  timestamp: string (ISO),
  processingTime: number (ms),
  riskLevel: "low" | "medium" | "high" | "critical",
  recommendation: string,
  
  detectedAnomalies: [
    {
      type: string,              // "Watermark Manipulation", etc.
      confidence: number (0-100),
      location: { x, y, width, height },  // Percentage-based
      severity: "critical" | "high" | "medium" | "low",
      explanation: string,
      detailedAnalysis: object   // Type-specific details
    }
  ],
  
  comparisonAnalysis: {
    templateMatch: number,
    historicalFraudSimilarity: number,
    institutionVerification: "verified" | "suspicious" | "failed",
    pastFraudCases: number,
    matchedHistoricalInstances: number
  },
  
  biometricAnalysis: {
    faceMatch: number,
    fingerprintMatch: number,
    livenessScore: number,
    antiSpoofingConfidence: number
  }
}
```

### Anomaly Object
```javascript
{
  type: string,                   // Anomaly type
  confidence: number,             // Confidence percentage
  location: {
    x: number,                    // X coordinate (0-100%)
    y: number,                    // Y coordinate (0-100%)
    width: number,                // Width (0-100%)
    height: number                // Height (0-100%)
  },
  severity: string,               // critical | high | medium | low
  explanation: string,            // Human-readable explanation
  detailedAnalysis: {             // Type-specific details
    [key]: value
  }
}
```

## üé® Styling & Theming

### Government Color Integration

All components use the Indian Government color palette:

```javascript
{
  navy: '#1C3664',        // Primary text, headers
  saffron: '#FF9933',     // Accents, warnings
  green: '#138808',       // Success, verified
  blue: '#0066CC',        // Links, interactive
  gold: '#D4AF37',        // Accents
  gray: '#F5F5F5-#333333' // Neutrals
}
```

### CSS Classes Applied

- `.gov-card` - Standard card styling
- `.gov-card-premium` - Premium card with saffron accent
- `.btn-gov-*` - Button variants
- `.badge-gov-*` - Badge styles
- `.status-*` - Status indicators

## üîÑ Usage Examples

### Basic Integration

```javascript
import { AIFraudDetector } from '../components/AIFraudDetection';

export default function DocumentPage() {
  const [detectionResult, setDetectionResult] = useState(null);

  return (
    <AIFraudDetector
      documentId="DOC-2025-001"
      documentData={{
        name: "Certificate of Enrollment",
        type: "Educational Document",
        uploadedAt: new Date().toISOString(),
      }}
      onDetectionComplete={(result) => {
        setDetectionResult(result);
        if (result.riskLevel === 'critical') {
          // Alert authority
          escalateToAuthority(result);
        }
      }}
      onAnomalyClick={(anomaly) => {
        console.log('User clicked anomaly:', anomaly);
      }}
    />
  );
}
```

### Advanced: Batch Processing

```javascript
import { detectFraudBatch } from '../services/aiDetectionService';

async function processMultipleDocuments() {
  const results = await detectFraudBatch(
    ['DOC-001', 'DOC-002', 'DOC-003'],
    (progress) => {
      console.log(`Progress: ${progress.percentage}%`);
    }
  );

  const fraudulentDocs = results.results.filter(
    r => r.riskLevel === 'critical'
  );

  return fraudulentDocs;
}
```

### Advanced: History & Comparison

```javascript
import { getDetectionHistory, compareWithTemplate } from '../services/aiDetectionService';

async function analyzeDocumentHistory() {
  // Get historical data
  const history = await getDetectionHistory('DOC-001');

  // Check consistency
  const isConsistent = history.consistent;

  // Compare with template
  const templateComparison = await compareWithTemplate(
    'DOC-001',
    'INST-2025-001'
  );

  return {
    history,
    templateComparison,
    recommendation: isConsistent ? 'approve' : 'review'
  };
}
```

## üéØ Integration Points

### StudentDashboard Integration

The AI Fraud Detector is integrated into the **Upload Tab** of StudentDashboard:

**Location:** `/src/dashboards/StudentDashboard.jsx` (Upload Tab)

**Implementation:**
```jsx
import { AIFraudDetector } from '../components/AIFraudDetection';

// Inside upload tab section
<AIFraudDetector
  documentId={selectedDoc?.id || uploadQueue[0]?.id || docs[0]?.id}
  documentData={{
    name: selectedDoc?.name || uploadQueue[0]?.name || docs[0]?.name,
    type: selectedDoc?.type || "Uploaded Document",
    uploadedAt: new Date().toISOString(),
  }}
  onDetectionComplete={(result) => {
    console.log("AI Detection completed:", result);
  }}
/>
```

### Other Dashboard Integration Points

#### CentreStaffDashboard
```jsx
// For verifying documents submitted by students
<AIFraudDetector
  documentId={submissionId}
  documentData={submissionMetadata}
  onDetectionComplete={handleCentreStaffVerification}
/>
```

#### SecurityDashboard
```jsx
// For security monitoring and alert generation
<AIFraudDetector
  documentId={flaggedDocumentId}
  documentData={documentMetadata}
  onDetectionComplete={handleSecurityAlert}
/>
```

#### AuthorityDashboard
```jsx
// For final review and decision-making
<AIFraudDetector
  documentId={escalatedDocumentId}
  documentData={escalationMetadata}
  onDetectionComplete={handleAuthorityDecision}
/>
```

## üß™ Testing Recommendations

### Unit Tests

```javascript
// Test service functions
describe('aiDetectionService', () => {
  test('detectFraud returns valid result structure', async () => {
    const result = await detectFraud('test-doc');
    expect(result).toHaveProperty('fraudProbability');
    expect(result).toHaveProperty('detectedAnomalies');
    expect(result.riskLevel).toMatch(/low|medium|high|critical/);
  });

  test('anomalies contain required fields', async () => {
    const result = await detectFraud('test-doc');
    result.detectedAnomalies.forEach(anomaly => {
      expect(anomaly).toHaveProperty('type');
      expect(anomaly).toHaveProperty('confidence');
      expect(anomaly).toHaveProperty('location');
      expect(anomaly).toHaveProperty('severity');
    });
  });
});
```

### Integration Tests

```javascript
// Test component rendering and interaction
describe('AIFraudDetector', () => {
  test('renders detection button when not loading', () => {
    const { getByText } = render(
      <AIFraudDetector documentId="test" />
    );
    expect(getByText(/Run AI Detection/)).toBeInTheDocument();
  });

  test('executes detection on button click', async () => {
    const { getByText } = render(
      <AIFraudDetector documentId="test" />
    );
    fireEvent.click(getByText(/Run AI Detection/));
    
    await waitFor(() => {
      expect(getByText(/Detection Complete/)).toBeInTheDocument();
    });
  });

  test('calls onDetectionComplete callback', async () => {
    const callback = jest.fn();
    render(
      <AIFraudDetector
        documentId="test"
        onDetectionComplete={callback}
      />
    );
    
    fireEvent.click(screen.getByText(/Run AI Detection/));
    
    await waitFor(() => {
      expect(callback).toHaveBeenCalled();
    });
  });
});
```

### E2E Tests

```javascript
// Test complete user workflow
describe('E2E: Document AI Verification', () => {
  test('User uploads document and runs AI detection', async () => {
    // Navigate to upload tab
    // Upload document
    // Run AI detection
    // Verify results displayed
    // Check anomalies highlighted
    // Verify recommendation shown
  });

  test('User can review anomalies and export report', async () => {
    // Run detection
    // Click on anomaly
    // Verify detailed view opens
    // Click export button
    // Verify file downloaded
  });
});
```

## üöÄ Performance Optimization

### Memoization

All components use `React.memo` and `useMemo` to prevent unnecessary re-renders:

```javascript
const AIFraudDetector = React.memo(function AIFraudDetector(props) {
  const riskColors = useMemo(() => ({...}), []);
  // Component uses memoized values
});
```

### Canvas Rendering

The AnomalyVisualizer uses canvas for efficient heatmap rendering instead of DOM elements.

### Lazy Loading

Components can be lazy-loaded using `React.lazy` for code splitting:

```javascript
const AIFraudDetector = lazy(() => import('../components/AIFraudDetection'));
```

## ‚ôø Accessibility

### ARIA Labels

All interactive elements have appropriate ARIA labels:

```jsx
<button
  aria-label="Start AI fraud detection"
  aria-pressed={loading}
>
  Run AI Detection
</button>
```

### Live Regions

Detection progress uses ARIA live regions for screen reader announcements:

```jsx
<div
  role="status"
  aria-live="polite"
  aria-atomic="true"
>
  {statusMessage}
</div>
```

### Keyboard Navigation

- Tab through all controls
- Enter/Space to activate buttons
- Arrow keys for slider control
- Esc to close modals

## üêõ Troubleshooting

### Issue: Detection takes too long
**Solution:** Latency is simulated (1-2 seconds). In production, optimize ML model loading and caching.

### Issue: Heatmap not rendering
**Solution:** Check browser canvas support and that `canvasRef` is properly mounted.

### Issue: Anomalies not displaying
**Solution:** Verify anomaly data structure matches expected format. Check console for errors.

### Issue: Component not updating after detection
**Solution:** Ensure `onDetectionComplete` callback is properly updating parent state.

## üìà Future Enhancements

1. **Real ML Model Integration**
   - Replace mock service with actual ML API calls
   - TensorFlow.js for client-side inference
   - Server-side model deployment

2. **Advanced Features**
   - OCR for text extraction and verification
   - Batch processing UI
   - Report generation and export
   - Historical trend analysis

3. **Biometric Integration**
   - Real face recognition API
   - Fingerprint scanning
   - Iris recognition
   - Liveness detection with video

4. **Performance**
   - Web Workers for heavy processing
   - IndexedDB for offline caching
   - Progressive Web App support
   - Service Worker integration

## üìö References

- **Mock Data Structure:** See `detectFraud()` in `aiDetectionService.js`
- **Component Architecture:** See component exports in `AIFraudDetection/index.js`
- **Integration Example:** See StudentDashboard.jsx Upload Tab
- **Styling Guide:** See `src/index.css` and `tailwind.config.js`

## üéì Learning Path

1. **Start Here:** Read this guide (10-15 min)
2. **Explore Components:** Review each component in AIFraudDetection folder (15-20 min)
3. **Understand Service:** Study aiDetectionService.js (10-15 min)
4. **Integrate:** Add to your dashboard (5-10 min)
5. **Customize:** Modify detection logic and styling (15-30 min)
6. **Test:** Run unit and integration tests (15-30 min)

---

**Status:** ‚úÖ Ready for Integration
**Last Updated:** November 27, 2025
**Version:** 1.0
